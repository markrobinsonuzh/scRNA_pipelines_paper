---
title: "Supplementary Figures relative to normalization"
author: "Pierre-Luc Germain"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output: html_document
---

```{r, include=FALSE}
if(!exists('FIG_NB')){
  FIG_NB <- 0
  getFigNb <- function(increment=FALSE){
    if(increment) FIG_NB <<- FIG_NB + 1
    FIG_NB
  }
}
```

```{r}
suppressPackageStartupMessages({
  library(ggplot2)
  library(cowplot)
  library(ComplexHeatmap)
  library(reshape2)
  library(dplyr)
  library(viridis)
  library(pipeComp)
})
theme_set(theme_cowplot(font_size = 11))
source("../misc_functions.R")

classifyNorms <- function(x){
  y <- rep("other", length(x))
  y[grep("sctransform",x)] <- "sctransform"
  y[grep("seurat",x)] <- "seurat"
  y[grep("scran",x)] <- "scran"
  y[grep("stableG",x)] <- "stableG"
  y
}
```



# Fig S`r getFigNb(TRUE)`

```{r covar, fig.width=8, fig.height=4.5}
res <- readRDS("../data/results_norm.rds")
renameNorm(evalHeatmap(res, step="dimreduction", c("log10_total_counts","log10_total_features"), what2="meanAbsCorr.covariate2", agg.by="norm", anno_legend=FALSE, scale=FALSE, row_split=classifyNorms(norm)))
```

### Fig S`r getFigNb()`
Mean per-subpopulation absolute correlation of the first 5 components with library size (left) and the number of detected features (right) across normalization procedures.

\newpage

# Fig S`r getFigNb(TRUE)`

```{r}
res <- readRDS("../data/scVI.rds")
res$evaluation$dimreduction$silhouette[[1]] <- res$evaluation$dimreduction$silhouette[[1]][with(res$evaluation$dimreduction$silhouette[[1]], filt=="filt.default" & (!(dr %in% c("scVI.latent","scVI.LD")) | norm=="norm.scVI")),]
res$evaluation$dimreduction$silhouette[[1]]$norm <- gsub("norm.seuratvst","sctransform",res$evaluation$dimreduction$silhouette[[1]]$norm)
res$evaluation$clustering <- res$evaluation$clustering[with(res$evaluation$clustering, filt=="filt.default" & (!(dr %in% c("scVI.latent","scVI.LD")) | norm=="norm.scVI")),]
res$evaluation$clustering$norm <- gsub("norm.seuratvst","sctransform",res$evaluation$clustering$norm)

H <- scrna_evalPlot_silh(res)

res$evaluation$clustering$delta.nbClust <- res$evaluation$clustering$n_clus-res$evaluation$clustering$true.nbClusts
H2 <- evalHeatmap(res, step="clustering", what=c("MI"), agg.by=c("norm","dr"), anno_legend=FALSE, width=unit(6.5,"cm")) +
  evalHeatmap(res, step="clustering", what="ARI", agg.by=c("norm","dr"), anno_legend=FALSE, filterExpr = n_clus==true.nbClusts, name="ARI at true k", title="ARI at true k" ) + 
  evalHeatmap(res, step="clustering", what=c("delta.nbClust"), value_format = "%.0f", scale=FALSE, col=circlize::colorRamp2(c(-3,0,9),c("red","white","blue")), value_cols = c("black","black"),agg.by=c("norm","dr"), anno_legend=FALSE, show_heatmap_legend = TRUE, heatmap_legend_param=list(direction="horizontal"))
```

```{r, fig.width=9, fig.height=5.5}
plot_grid(grid.grabExpr(draw(H)), grid.grabExpr(draw(H2, heatmap_legend_side="bottom")), ncol=1, labels = LETTERS[1:2], rel_heights=c(3,4))
```

### Fig S`r getFigNb()`

**scVI evaluation. A:** Average silhouette width per subpopulation using either sctransform, scran or scVI normalization followed by Seurat PCA, or the scVI latent space (latent) or imputed values (LD) of the linear decoder. **B:** Clustering accuracy across the same methods followed by Seurat clustering.

\newpage


# Fig S`r getFigNb(TRUE)`

```{r norm_nbClusters, fig.width=8, fig.height=8.5}
res <- readRDS("../data/results_norm.rds")
res <- res$evaluation$clustering
res2 <- res[which(res$norm %in% c("norm.scran.scaled", "norm.scran", "norm.seurat", "norm.sctransform", "norm.stableGsum") & res$resolution<4),]
res2 <- res2[grep("simMix",res2$dataset,invert=TRUE),]
res2$dataset <- droplevels(res2$dataset)
res2$delta.nbClusters <- res2$n_clus-res2$true.nbClusts
res3 <- aggregate(res2[,"delta.nbClusters"], by=res2[,c("dataset","dims","resolution","norm")], FUN=mean)
colnames(res3)[5] <- "nb"
res3$norm <- gsub("norm.","",res3$norm, fixed=T)

ll <- lapply(split(res3, res3$dataset), FUN=function(x){
  ggplot(x, aes(factor(resolution), factor(dims), fill=nb)) + stat_bin2d() + 
    scale_fill_viridis() + xlab("Resolution") + ylab("dims") +
    facet_grid(.~norm)
})
for(i in names(ll)){
  ll[[i]] <- ll[[i]] + ggtitle(i)
  if(i==names(ll)[length(ll)]){
    ll[[i]] <- ll[[i]] + theme(axis.text.x = element_text(angle = 90, hjust = 1))
  }else{
    ll[[i]] <- ll[[i]] + theme(axis.title.x=element_blank(), axis.text.x=element_blank(), axis.ticks.x=element_blank())
  }
}
ll[[4]] <- ll[[4]] + ylab("Number of dimensions")

mod <- summary(lm(n_clus~dataset+norm+dims+resolution, data=res2))
plot_grid(plotlist = ll[-2], nrow=6, rel_heights=c(1,1,1,1,1,1.5))
```

### Fig S`r getFigNb()`
Mean difference between the number of detected clusters and the number of real subpopulations, depending on the normalization method, the resolution and the number of dimensions used. The Kumar dataset is not shown here due to a lack of variation in the number of clusters detected. A rough ANOVA on `nbClusters~dataset+norm+dims+resolution` suggests that seuratvst (sctransform) is associated with a higher number of clusters (p~`r round(mod$coefficients["normnorm.sctransform",4],3)`).

\newpage 

# Fig S`r getFigNb(TRUE)`

```{r VST, echo=FALSE, out.width = '100%'}
knitr::include_graphics("vst.png")
```

### Fig S`r getFigNb()`
Relationship of the variance with mean count after `sctranform`'s variance stabilizing transformation.

\newpage

# Fig S`r getFigNb(TRUE)`

```{r, fig.width=7.5, fig.height=6}
res <- readRDS("../data/results_norm.rds")
res <- res$elapsed$stepwise$normalization
ag <- aggregate(res[,"elapsed",drop=FALSE], by=res[,c("dataset","norm")], FUN=mean)
cols <- pipeComp::getQualitativePalette(9)
names(cols) <- levels(ag$dataset)
ggplot(ag, aes(norm, elapsed)) + geom_boxplot() + geom_point(aes(colour=dataset)) + 
  coord_flip() + scale_colour_manual(values=cols) + xlab("") + ylab("Time (s)")
```

### Fig S`r getFigNb()`
Running time of the normalization methods.
